### use # to comment out the configure item

################ Datasets(Input/Output) ################
workspace=/path/to/your/CA-BERT-MLP/folder/
datasets_fold=data/Manual_FB
all_labels=[T,V,SD,ED]
log_dir=logs
output_dir=output

################ Model Configuration ################
sentence_fragment_length=10
max_sequence_length=128
# int, cautions! set as a LARGE number as possible,
# this will be kept during training and inferring, text having length larger than this will be truncated.

CUDA_VISIBLE_DEVICES=0
# coincides with tf.CUDA_VISIBLE_DEVICES

bert_model_hub=https://tfhub.dev/google/bert_chinese_L-12_H-768_A-12/1
bert_warmup_proportion=0.1

num_gru_layers=1
gru_hidden_size=200

dropout_keep_prob=1.0

l2_lambda=0

################ Training Settings ###
epoch=60
batch_size=3

model_fold=model